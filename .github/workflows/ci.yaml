name: Data Processing Pipeline

on:
  workflow_dispatch:
  push:
    branches:
      - main

jobs:
  download-and-process-data:
    runs-on: ubuntu-latest
    timeout-minutes: 120  # Set the timeout to 120 minutes

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Set up Airflow
        run: |
          export AIRFLOW_HOME=~/airflow
          mkdir -p $AIRFLOW_HOME/dags
          cp ./dags/retrieve_dataset_dag.py $AIRFLOW_HOME/dags/
          airflow db init
          airflow standalone &> /tmp/airflow.log &

      - name: Show Airflow DAG execution log
        run: |
          curl -s "http://localhost:8080/api/v1/dags/data_processing/dagRuns" -H "Content-Type: application/json" | jq '.'